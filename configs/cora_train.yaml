defaults:
  - _self_
  - callbacks: none
  - logger: null # set logger here or use command line (e.g. `python train.py logger=tensorboard`)
  - trainer: cpu
  - paths: default
  - extras: default
  - hydra: default
  - hparams_search: null
  - optional local: default
  - debug: null
#只需要配置data和model
data:
  _target_: src.data.cora_datamodule.CoraDataModule
  data_dir: ${paths.data_dir}
  batch_size: 64
  num_workers: 0
  proprecess: 'addone'
model:
  _target_: src.models.cora_module.CoraLitModule
  #优化器
  optimizer:
    _target_: torch.optim.Adam
    _partial_: true
    lr: 0.01
    weight_decay: 0.0
  #损失函数
  loss:
    _target_: torch.nn.CrossEntropyLoss
  #学习率调整
  scheduler:
    _target_: torch.optim.lr_scheduler.ReduceLROnPlateau
    _partial_: true
    mode: min
    factor: 0.1
    patience: 10
  #网络backbone
  gcn:
    _target_: src.models.components.gcn.GCN
    input_size: 1433
    hidden_size: 64
    output_size: 7
  gat:
    _target_: src.models.components.gat.GAT
    input_size: 7
    hidden_size: 28
    output_size: 7
  mlp:
    _target_: src.models.components.mlp.MLP
    input_size: 7
    hidden_size: 64
    output_size: 7



  # compile model for faster training with pytorch 2.0
  compile: false

#任务名
task_name: "train"

tags: ["dev"]
# set False to skip model training
train: True

# evaluate on test set, using best model weights achieved during training
# lightning chooses best weights based on the metric specified in checkpoint callback
test: null

# simply provide checkpoint path to resume training
ckpt_path: null

# seed for random number generators in pytorch, numpy and python.random
seed: null



#dataset
#model
#data
#pre和post
