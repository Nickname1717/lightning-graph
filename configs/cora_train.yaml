defaults:
  - _self_
  - callbacks: none
  - logger: null # set logger here or use command line (e.g. `python train.py logger=tensorboard`)
  - trainer: cpu
  - paths: default
  - extras: default
  - hydra: default
#只需要配置data和model
data:
  _target_: src.data.cora_datamodule.CoraDataModule
  data_dir: ${paths.data_dir}
  batch_size: 64
  num_workers: 0
  proprecess: 'addone'
model:
  _target_: src.models.cora_module.CoraLitModule
  optimizer:
    _target_: torch.optim.Adam
    _partial_: true
    lr: 0.01
    weight_decay: 0.0

  loss:
    _target_: torch.nn.CrossEntropyLoss

  scheduler:
    _target_: torch.optim.lr_scheduler.ReduceLROnPlateau
    _partial_: true
    mode: min
    factor: 0.1
    patience: 10

  net:
    gcn:
      _target_: src.models.components.gcn.GCN
      input_size: 1433
      hidden_size: 64
      output_size: 7
    gat:
      _target_: src.models.components.gat.GAT
      input_size: 7
      hidden_size: 28
      output_size: 7
  decoder:
    mlp:
      _target_: src.models.components.mlp.MLP
      input_size: 7
      hidden_size: 64
      output_size: 7



  # compile model for faster training with pytorch 2.0
  compile: false

#任务名
task_name: "train"

tags: ["dev"]
# set False to skip model training
train: True

# evaluate on test set, using best model weights achieved during training
# lightning chooses best weights based on the metric specified in checkpoint callback
test: null

# simply provide checkpoint path to resume training
ckpt_path: ${paths.root_dir}\ckpt\

# seed for random number generators in pytorch, numpy and python.random
seed: null



#dataset
#model
#data
#pre和post
